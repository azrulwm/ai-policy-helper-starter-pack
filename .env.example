# AI Policy Helper Configuration

# LLM Provider Settings
# Options: stub | openai | ollama
LLM_PROVIDER=stub

# OpenAI Configuration (required if LLM_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/account/api-keys
# Format: sk-proj-... or sk-...
OPENAI_API_KEY=

# Ollama Configuration (required if LLM_PROVIDER=ollama)
OLLAMA_HOST=http://ollama:11434

# Vector Store Settings
# Options: qdrant | memory
VECTOR_STORE=qdrant

# Document Processing Settings
CHUNK_SIZE=700
CHUNK_OVERLAP=80

# System Settings
EMBEDDING_MODEL=local-384
COLLECTION_NAME=policy_helper

# Frontend
NEXT_PUBLIC_API_BASE=http://localhost:8000
